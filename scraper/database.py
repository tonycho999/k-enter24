import os
from supabase import create_client, Client
from dotenv import load_dotenv
import config  # ê°™ì€ í´ë”ì— ìˆìœ¼ë¯€ë¡œ ë°”ë¡œ import ê°€ëŠ¥

load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# ì—°ê²° ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
try:
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
except:
    supabase = None

def save_news(data_list):
    """ë‰´ìŠ¤ ë°ì´í„° ì €ì¥"""
    if not supabase or not data_list: return
    try:
        supabase.table("live_news").upsert(data_list).execute()
        print(f"   ğŸ’¾ Saved {len(data_list)} articles.")
    except Exception as e:
        print(f"   âš ï¸ DB Save Error: {e}")

def cleanup_old_news(category):
    """ì¹´í…Œê³ ë¦¬ë³„ ì˜¤ë˜ëœ ë‰´ìŠ¤ ì‚­ì œ"""
    if not supabase: return
    try:
        # ê°œìˆ˜ í™•ì¸
        resp = supabase.table("live_news").select("id", count="exact").eq("category", category).execute()
        count = resp.count
        
        if count > config.MAX_ITEMS_PER_CATEGORY:
            limit = count - config.MAX_ITEMS_PER_CATEGORY
            # ì˜¤ë˜ëœ ìˆœìœ¼ë¡œ ID ì¡°íšŒ
            old_rows = supabase.table("live_news").select("id").eq("category", category).order("created_at", desc=False).limit(limit).execute()
            ids = [row['id'] for row in old_rows.data]
            
            if ids:
                supabase.table("live_news").delete().in_("id", ids).execute()
                print(f"   ğŸ§¹ Cleaned up {len(ids)} old items.")
    except Exception as e:
        print(f"   âš ï¸ Cleanup Error: {e}")
