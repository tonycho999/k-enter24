import asyncio
import json
from playwright.async_api import async_playwright

class ChartEngine:
    def __init__(self):
        self.ua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"

    async def get_chart_data(self, category, run_count):
        """ì¹´í…Œê³ ë¦¬ë³„ 3ì‚¬ ë¡œí…Œì´ì…˜ ë° ì‹¤íŒ¨ ì‹œ ë°±ì—… ì „í™˜"""
        # ë¡œí…Œì´ì…˜ íƒ€ê²Ÿ ì„¤ì •
        rotation_map = {
            "k-pop": ["melon", "genie", "bugs"],
            "k-drama": ["nielsen", "naver_drama", "daum_drama"],
            "k-movie": ["kobis", "naver_movie", "daum_movie"],
            "k-entertain": ["nielsen_ent", "naver_ent", "daum_ent"]
        }
        
        targets = rotation_map.get(category, ["naver_search"])
        target = targets[run_count % 3]
        
        print(f"ğŸ” [Attempt] Category: {category} | Source: {target}")
        
        # 1. ë©”ì¸ íƒ€ê²Ÿ ì‹œë„
        data = await self._scrape_entry(target, category)
        
        # 2. ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ë°±ì—…(ë„¤ì´ë²„ í†µí•©ê²€ìƒ‰) ì‹œë„
        if not data:
            print(f"âš ï¸ {target} failed. Switching to Emergency Backup (Naver Search)...")
            data = await self._scrape_entry("naver_search", category)
            
        return data

    async def _scrape_entry(self, target, category):
        """ì‹¤ì œ ìŠ¤í¬ë˜í•‘ ë¡œì§ (ì—ëŸ¬ ë°œìƒ ì‹œ None ë°˜í™˜)"""
        async with async_playwright() as p:
            try:
                browser = await p.chromium.launch(headless=True)
                context = await browser.new_context(user_agent=self.ua)
                page = await context.new_page()
                
                # íƒ€ê²Ÿë³„ ë¶„ê¸° (ì˜ˆì‹œ: ë©œë¡ )
                if target == "melon":
                    await page.goto("https://www.melon.com/chart/index.htm", timeout=30000)
                    # ... ê¸°ì¡´ ë©œë¡  ë¡œì§ ...
                elif target == "naver_search":
                    # í†µí•© ê²€ìƒ‰ ë°±ì—… ë¡œì§
                    query = f"{category} ìˆœìœ„"
                    await page.goto(f"https://search.naver.com/search.naver?query={query}")
                    # ... ë„¤ì´ë²„ ë¦¬ìŠ¤íŠ¸ ë¡œì§ ...
                
                # ë°ì´í„° ì¶”ì¶œ í›„ ì„±ê³µí•˜ë©´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜, ì‹¤íŒ¨í•˜ë©´ None
                # (ì¤‘ê°„ ìƒëµ: ì‹¤ì œ íƒœê·¸ ì¶”ì¶œ ì½”ë“œ)
                
                await browser.close()
                return data if data else None
            except Exception as e:
                print(f"âŒ Scrape Fatal: {e}")
                # ì—¬ê¸°ì„œ ì—ëŸ¬ ë¡œê·¸ë¥¼ ë‚¨ê²¨ ë‚˜ì¤‘ì— Groqê°€ ë¶„ì„í•˜ê²Œ í•¨
                with open("error_structure.html", "w", encoding="utf-8") as f:
                    f.write(await page.content())
                return None
