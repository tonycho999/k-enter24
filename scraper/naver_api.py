# scraper/naver_api.py
import os
import time
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv

load_dotenv(os.path.join(os.path.dirname(__file__), '../.env'))
CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

def search_news_api(keyword, display=10):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API (ìµœì‹ ìˆœ ì •ë ¬ ì ìš©)"""
    if not CLIENT_ID or not CLIENT_SECRET:
        print(f"   ğŸš¨ [Naver API Error] Client ID or Secret is MISSING.")
        return []

    url = "https://openapi.naver.com/v1/search/news.json"
    
    headers = {
        "X-Naver-Client-Id": CLIENT_ID.strip(), 
        "X-Naver-Client-Secret": CLIENT_SECRET.strip()
    }
    
    # [í•µì‹¬ ìˆ˜ì •] sort: 'sim'(ì •í™•ë„) -> 'date'(ìµœì‹ ìˆœ)
    # ì´ë ‡ê²Œ í•´ì•¼ 'ì˜›ë‚  ëª…ì‘'ì´ ì•„ë‹ˆë¼ 'ì§€ê¸ˆ ë°©ì˜ ì¤‘ì¸ ë“œë¼ë§ˆ' ê¸°ì‚¬ê°€ ëœ¹ë‹ˆë‹¤.
    params = {
        "query": keyword, 
        "display": display, 
        "sort": "date" 
    }

    try:
        resp = requests.get(url, headers=headers, params=params, timeout=5)
        
        if resp.status_code == 200:
            items = resp.json().get('items', [])
            return items
        else:
            print(f"   ğŸš¨ [Naver API Fail] Status: {resp.status_code}")
            return []
            
    except Exception as e:
        print(f"   ğŸš¨ [Naver Connection Error] {e}")
        return []

def crawl_article(url):
    """ë‰´ìŠ¤ ë³¸ë¬¸ ë° ì´ë¯¸ì§€ ì¶”ì¶œ"""
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    if "news.naver.com" not in url:
        return {"text": "", "image": ""}

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    try:
        time.sleep(0.3) 
        resp = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(resp.text, 'html.parser')

        content = ""
        # ë³¸ë¬¸ ì¶”ì¶œ ë¡œì§ ê°•í™” (ì—°ì˜ˆ ë‰´ìŠ¤ëŠ” div idê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        for selector in ["#dic_area", "#articeBody", "#newsEndContents", ".go_trans._article_content"]:
            el = soup.select_one(selector)
            if el:
                for tag in el(['script', 'style', 'a', 'iframe', 'span']):
                    tag.decompose()
                content = el.get_text(strip=True)
                break
        
        image_url = ""
        og_img = soup.select_one('meta[property="og:image"]')
        if og_img:
            image_url = og_img.get('content', '')

        return {"text": content[:3000], "image": image_url}

    except Exception:
        return {"text": "", "image": ""}
