import os
import sys
import json
import time
import random
import requests
from bs4 import BeautifulSoup
from supabase import create_client, Client
from datetime import datetime
from dotenv import load_dotenv
from groq import Groq
from urllib.parse import urljoin

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
sys.stdout.reconfigure(encoding='utf-8')

supabase_url = os.environ.get("NEXT_PUBLIC_SUPABASE_URL")
supabase_key = os.environ.get("NEXT_PUBLIC_SUPABASE_ANON_KEY")
groq_api_key = os.environ.get("GROQ_API_KEY")
naver_client_id = os.environ.get("NAVER_CLIENT_ID")
naver_client_secret = os.environ.get("NAVER_CLIENT_SECRET")

supabase: Client = create_client(supabase_url, supabase_key)
groq_client = Groq(api_key=groq_api_key)

# [ìˆ˜ì •] ì‹œë„í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (ìµœì‹ /ê³ ì„±ëŠ¥ ìˆœì„œ)
MODELS_TO_TRY = [
    "llama-3.3-70b-versatile", # ìµœì‹  ìµœê³  ì‚¬ì–‘
    "llama-3.1-70b-versatile", # ì•ˆì •ì ì¸ ê³ ì‚¬ì–‘
    "llama-3.1-8b-instant",    # ë¹ ë¥´ê³  ê°€ë²¼ìš´ ëª¨ë¸ (ìµœí›„ ë³´ë£¨)
    "mixtral-8x7b-32768"       # ëŒ€ì•ˆ ëª¨ë¸
]

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
    'Referer': 'https://news.naver.com/'
}

SEARCH_KEYWORDS = [
    "ë°°ìš°", "ê°€ìˆ˜", "ì»´ë°±", "ë°ë·”", "ìºìŠ¤íŒ…", "ì¢…ì˜", "ê°œë´‰", 
    "ë…ì ", "ë¹Œë³´ë“œ", "ê³µê°œì˜ˆì •", "ì‹œì²­ë¥  1ìœ„", "ì‹ ì¸ë°°ìš°", "ì œì‘ë°œí‘œíšŒ", "ì–´ì›Œë“œ"
]

# 2. ë­í‚¹ ìˆ˜ì§‘ (ì…€ë ‰í„° ë³´ê°•)
def get_naver_ranking_30():
    print("ğŸ“¡ ë„¤ì´ë²„ ì—°ì˜ˆ ì‹¤ì‹œê°„ ë­í‚¹ 30 ìˆ˜ì§‘ ì‹œë„...")
    ranking_url = "https://entertain.naver.com/ranking"
    try:
        res = requests.get(ranking_url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        items = []
        news_links = soup.select('.rank_lst li a.tit') or soup.select('.tit_area a') or soup.select('a.tit')
        
        print(f"ğŸ” ë­í‚¹ í˜ì´ì§€ì—ì„œ {len(news_links)}ê°œì˜ ì ì¬ì  ë§í¬ ë°œê²¬")
        
        for i, a in enumerate(news_links[:30]):
            title = a.get_text(strip=True)
            link = urljoin(ranking_url, a['href'])
            if title and link:
                items.append({'title': title, 'link': link, 'is_ranking': True})
        return items
    except Exception as e:
        print(f"âš ï¸ ë­í‚¹ ìˆ˜ì§‘ ì—ëŸ¬: {e}")
        return []

def get_naver_api_news(keyword):
    import urllib.parse
    import urllib.request
    encText = urllib.parse.quote(keyword)
    url = f"https://openapi.naver.com/v1/search/news?query={encText}&display=10&sort=sim"
    req = urllib.request.Request(url)
    req.add_header("X-Naver-Client-Id", naver_client_id)
    req.add_header("X-Naver-Client-Secret", naver_client_secret)
    try:
        res = urllib.request.urlopen(req)
        items = json.loads(res.read().decode('utf-8')).get('items', [])
        return [{'title': i['title'], 'link': i['link'], 'is_ranking': False} for i in items]
    except: return []

def get_article_details(link):
    try:
        res = requests.get(link, headers=HEADERS, timeout=7)
        soup = BeautifulSoup(res.text, 'html.parser')
        og_image = soup.find('meta', property='og:image')
        return og_image['content'] if og_image else None
    except: return None

# 3. [í•µì‹¬] AI í¸ì§‘ì¥: ëª¨ë¸ ìˆœì°¨ ì‹œë„ ë¡œì§ ì ìš©
def ai_chief_editor(news_list):
    raw_text = "\n".join([f"[{i}] {n['title']}" for i, n in enumerate(news_list)])
    
    prompt = f"""
    Role: K-ENTER 24 Chief Editor.
    Task: Categorize news into EXACTLY one of these: [k-pop, k-drama, k-movie, k-entertain].
    Output MUST be in JSON format.
    
    Raw News:
    {raw_text}
    
    JSON Output Format:
    {{
        "articles": [
            {{
                "original_index": 0,
                "category": "k-pop",
                "eng_title": "Headline in English",
                "summary": "1 sentence English summary",
                "reactions": {{"excitement": 70, "shock": 30, "sadness": 0}}
            }}
        ]
    }}
    """

    for model_name in MODELS_TO_TRY:
        try:
            print(f"ğŸ¤– AI ë¶„ì„ ì‹œë„ ì¤‘... (ëª¨ë¸: {model_name})")
            res = groq_client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=model_name,
                response_format={"type": "json_object"}
            )
            return json.loads(res.choices[0].message.content)
        except Exception as e:
            print(f"âš ï¸ {model_name} ì‹¤íŒ¨: {e}. ë‹¤ìŒ ëª¨ë¸ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤...")
            continue # ë‹¤ìŒ ëª¨ë¸ë¡œ ì‹œë„
            
    print("âŒ ëª¨ë“  AI ëª¨ë¸ ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    return None

def run():
    wait_time = random.randint(60, 600)
    print(f"ğŸ•’ ë³´ì•ˆì„ ìœ„í•´ {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì‹œì‘í•©ë‹ˆë‹¤...")
    time.sleep(wait_time)

    print(f"=== {datetime.now()} ê³ ê°€ìš©ì„± ìˆ˜ì§‘ ëª¨ë“œ ê°€ë™ ===")
    
    all_raw_news = get_naver_ranking_30()
    for kw in SEARCH_KEYWORDS:
        all_raw_news.extend(get_naver_api_news(kw))
    
    if not all_raw_news:
        print("âŒ ìˆ˜ì§‘ëœ ì›ì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    analysis = ai_chief_editor(all_raw_news)
    if not analysis: return

    saved = 0
    for art in analysis.get('articles', []):
        idx = art['original_index']
        if idx >= len(all_raw_news): continue
        item = all_raw_news[idx]
        
        if supabase.table("live_news").select("id").eq("link", item['link']).execute().data:
            continue
            
        img = get_article_details(item['link'])
        if not img: img = f"https://placehold.co/600x400/111/cyan?text={art['category']}"

        try:
            data = {
                "category": art['category'],
                "title": art['eng_title'],
                "summary": art['summary'],
                "link": item['link'],
                "image_url": img,
                "reactions": art['reactions'],
                "is_ranking": item.get('is_ranking', False),
                "created_at": datetime.now().isoformat()
            }
            supabase.table("live_news").insert(data).execute()
            saved += 1
            print(f"âœ… [{art['category']}] ì €ì¥ ì™„ë£Œ")
        except: pass

    print(f"=== ìµœì¢… ì™„ë£Œ: {saved}ê°œ ë‰´ìŠ¤ ì—…ë°ì´íŠ¸ ===")

if __name__ == "__main__":
    run()
