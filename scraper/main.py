# scraper/main.py
import sys
import time
from datetime import datetime
import config
import processor

def main():
    print(f"ğŸ¤– GitHub Action Scraper Started at {datetime.now()} (UTC)")
    
    # [ìˆ˜ì •ë¨] ì‹œê°„ ê³„ì‚° ì—†ì´ ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ ìˆœì„œëŒ€ë¡œ ë‹¤ ì‹¤í–‰
    results = {"success": 0, "failed": 0}

    for category in config.CATEGORY_ORDER:
        try:
            print(f"\n==================================================")
            print(f"ğŸƒ Starting Category: {category}")
            
            # ë¡œì§ ì‹¤í–‰
            processor.run_category_process(category)
            
            print(f"âœ… Finished: {category}")
            results["success"] += 1
            
            # ì¹´í…Œê³ ë¦¬ ì‚¬ì´ì— 5ì´ˆ íœ´ì‹ (API ê³¼ë¶€í•˜ ë°©ì§€)
            time.sleep(5)
            
        except Exception as e:
            print(f"ğŸš¨ Error in {category}: {e}")
            results["failed"] += 1
            # ì—ëŸ¬ê°€ ë‚˜ë„ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ëŠ” ê³„ì† ì§„í–‰ (continue)
            continue

    print(f"\nğŸ‰ Batch Job Completed. Success: {results['success']}, Failed: {results['failed']}")
    
    # í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨í–ˆìœ¼ë©´ ê¹ƒí—ˆë¸Œì— ê²½ê³  í‘œì‹œ (ì„ íƒì‚¬í•­, ì§€ê¸ˆì€ ê·¸ëƒ¥ ì„±ê³µ ì²˜ë¦¬)
    sys.exit(0)

if __name__ == "__main__":
    main()
