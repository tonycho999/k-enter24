name: K-Enter 24 Auto Scraper

on:
  # 스케줄러: 나중에 자동화를 시작하려면 아래 주석(#)을 해제하세요.
  # schedule:
  #   - cron: '11 * * * *'
  
  workflow_dispatch: # GitHub Actions 탭에서 버튼을 눌러 수동 실행 가능

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # requirements.txt에 openai, groq, supabase, requests가 포함되어 있어야 합니다.
          pip install -r scraper/requirements.txt

      - name: Run Scraper
        env:
          # [Database 설정]
          # GitHub Secrets에 SUPABASE_URL이 없으면 NEXT_PUBLIC_SUPABASE_URL을 대신 사용합니다.
          SUPABASE_URL: ${{ secrets.SUPABASE_URL || secrets.NEXT_PUBLIC_SUPABASE_URL }}
          
          # 쓰기 권한을 위해 SERVICE_ROLE_KEY가 권장되지만, 없다면 ANON_KEY를 시도합니다.
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY || secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          
          # [AI API 설정]
          PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          
          # [Naver API 설정]
          NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
          NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
          
          # [디버깅용 실행 번호]
          RUN_COUNT: ${{ github.run_number }}
        
        run: |
          cd scraper
          python main.py
